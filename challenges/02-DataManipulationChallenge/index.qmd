---
title: "Data Manipulation Challenge"
subtitle: "A Mental Model for Method Chaining in Pandas"
format:
  html: default
  pdf: default
execute:
  echo: true
  eval: true
---

# ðŸ”— Data Manipulation Challenge - A Mental Model for Method Chaining in Pandas

::: {.callout-important}
## ðŸ“Š Challenge Requirements In Section [Student Analysis Section](#student-analysis-section)
- Complete all seven mental models of data manipulation using method chaining
- Create visualizations that demonstrate your understanding of the data
- Do not `echo` the code that creates the visualizations
:::

## The Problem: Mastering Data Manipulation Through Method Chaining

**Core Question:** How can we efficiently manipulate datasets using pandas method chaining to answer complex business questions?

**The Challenge:** Real-world data analysis requires combining multiple data manipulation techniques in sequence. Rather than creating intermediate variables at each step, method chaining allows us to write clean, readable code that flows logically from one operation to the next.

**Our Approach:** We'll work with ZappTech's shipment data to answer critical business questions about service levels and cross-category orders, using the seven mental models of data manipulation through pandas method chaining.

::: {.callout-warning}
## âš ï¸ AI Partnership Required

This challenge pushes boundaries intentionally. You'll tackle problems that normally require weeks of study, but with Cursor AI as your partner (and your brain keeping it honest), you can accomplish more than you thought possible.

**The new reality:** The four stages of competence are Ignorance â†’ Awareness â†’ Learning â†’ Mastery. AI lets us produce Mastery-level work while operating primarily in the Awareness stage. I focus on awareness training, you leverage AI for execution, and together we create outputs that used to require years of dedicated study.
:::

## The Seven Mental Models of Data Manipulation

The seven most important ways we manipulate datasets are:

1. **Assign:** Add new variables with calculations and transformations
2. **Subset:** Filter data based on conditions or select specific columns
3. **Drop:** Remove unwanted variables or observations
4. **Sort:** Arrange data by values or indices
5. **Aggregate:** Summarize data using functions like mean, sum, count
6. **Merge:** Combine information from multiple datasets
7. **Split-Apply-Combine:** Group data and apply functions within groups


## Data and Business Context

We analyze ZappTech's shipment data, which contains information about product deliveries across multiple categories. This dataset is ideal for our analysis because:

- **Real Business Questions:** CEO wants to understand service levels and cross-category shopping patterns
- **Multiple Data Sources:** Requires merging shipment data with product category information
- **Complex Relationships:** Service levels may vary by product category, and customers may order across categories
- **Method Chaining Practice:** Perfect for demonstrating all seven mental models in sequence

## Data Loading and Initial Exploration

Let's start by loading the ZappTech shipment data and understanding what we're working with.

```{python}
#| label: load-data
#| echo: true
#| message: false
#| warning: false

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta

# Load the shipment data
shipments_df = pd.read_csv(
    "https://raw.githubusercontent.com/flyaflya/persuasive/main/shipments.csv", 
    parse_dates=['plannedShipDate', 'actualShipDate']
)

# Load product line data
product_line_df = pd.read_csv(
    "https://raw.githubusercontent.com/flyaflya/persuasive/main/productLine.csv"
)

# Reduce dataset size for faster processing (as in original notebook)
shipments_df = shipments_df.head(4000)

print("Shipments data shape:", shipments_df.shape)
print("\nShipments data columns:", shipments_df.columns.tolist())
print("\nFirst few rows of shipments data:")
print(shipments_df.head())

print("\n" + "="*50)
print("Product line data shape:", product_line_df.shape)
print("\nProduct line data columns:", product_line_df.columns.tolist())
print("\nFirst few rows of product line data:")
print(product_line_df.head())
```

::: {.callout-note}
## ðŸ’¡ Understanding the Data

**Shipments Data:** Contains individual line items for each shipment, including:
- `shipID`: Unique identifier for each shipment
- `partID`: Product identifier
- `plannedShipDate`: When the shipment was supposed to go out
- `actualShipDate`: When it actually shipped
- `quantity`: How many units were shipped

**Product Line Data:** Contains product category information:
- `partID`: Links to shipments data
- `productLine`: The category each product belongs to

**Business Questions We'll Answer:**
1. Does service level (on-time shipments) vary across product categories?
2. How often do orders include products from more than one category?
:::

## The Seven Mental Models: A Progressive Learning Journey

Now we'll work through each of the seven mental models using method chaining, starting simple and building complexity.

### 1. Assign: Adding New Variables

**Mental Model:** Create new columns with calculations and transformations.

Let's start by calculating whether each shipment was late:

```{python}
#| label: mental-model-1-assign
#| echo: true

# Simple assignment - calculate if shipment was late
shipments_with_lateness = (
    shipments_df
    .assign(
        is_late=lambda df: df['actualShipDate'] > df['plannedShipDate'],
        days_late=lambda df: (df['actualShipDate'] - df['plannedShipDate']).dt.days
    )
)

print("Added lateness calculations:")
print(shipments_with_lateness[['shipID', 'plannedShipDate', 'actualShipDate', 'is_late', 'days_late']].head())
```

::: {.callout-tip}
## ðŸ’¡ Method Chaining Tip for New Python Users

**Why use `lambda df:`?** When chaining methods, we need to reference the current state of the dataframe. The `lambda df:` tells pandas "use the current dataframe in this calculation." Without it, pandas would look for a variable called `df` that doesn't exist.

**Alternative approach:** You could also write this as separate steps, but method chaining keeps related operations together and makes the code more readable.
:::

### 2. Subset: Filtering Data

**Mental Model:** Select specific rows or columns based on conditions.

Let's filter for only late shipments and see what we find:

```{python}
#| label: mental-model-2-subset
#| echo: true

# Filter for late shipments only
late_shipments = (
    shipments_with_lateness
    .query('is_late == True')  # Filter rows where is_late is True
    .filter(['shipID', 'partID', 'plannedShipDate', 'actualShipDate', 'days_late'])  # Select specific columns
)

print(f"Found {len(late_shipments)} late shipments out of {len(shipments_with_lateness)} total")
print("\nLate shipments sample:")
print(late_shipments.head())
```

::: {.callout-note}
## ðŸ” Understanding the Methods

- **`.query()`**: Filter rows based on conditions (like SQL WHERE clause)
- **`.filter()`**: Select specific columns by name
- **Alternative**: You could use `.loc[]` for more complex filtering, but `.query()` is often more readable
:::

### 3. Drop: Removing Unwanted Data

**Mental Model:** Remove columns or rows you don't need.

Let's clean up our data by removing unnecessary columns:

```{python}
#| label: mental-model-3-drop
#| echo: true

# Create a cleaner dataset by dropping unnecessary columns
clean_shipments = (
    shipments_with_lateness
    .drop(columns=['quantity'])  # Drop quantity column (not needed for our analysis)
    .dropna(subset=['plannedShipDate', 'actualShipDate'])  # Remove rows with missing dates
)

print(f"Cleaned dataset: {len(clean_shipments)} rows, {len(clean_shipments.columns)} columns")
print("Remaining columns:", clean_shipments.columns.tolist())
```

### 4. Sort: Arranging Data

**Mental Model:** Order data by values or indices.

Let's sort by lateness to see the worst offenders:

```{python}
#| label: mental-model-4-sort
#| echo: true

# Sort by days late (worst first)
sorted_by_lateness = (
    clean_shipments
    .sort_values('days_late', ascending=False)  # Sort by days_late, highest first
    .reset_index(drop=True)  # Reset index to be sequential
)

print("Shipments sorted by lateness (worst first):")
print(sorted_by_lateness[['shipID', 'partID', 'days_late', 'is_late']].head(10))
```

### 5. Aggregate: Summarizing Data

**Mental Model:** Calculate summary statistics across groups or the entire dataset.

Let's calculate overall service level metrics:

```{python}
#| label: mental-model-5-aggregate
#| echo: true

# Calculate overall service level metrics
service_metrics = (
    clean_shipments
    .agg({
        'is_late': ['count', 'sum', 'mean'],  # Count total, count late, calculate percentage
        'days_late': ['mean', 'max']  # Average and maximum days late
    })
    .round(3)
)

print("Overall Service Level Metrics:")
print(service_metrics)

# Calculate percentage on-time directly from the data
on_time_rate = (1 - clean_shipments['is_late'].mean()) * 100
print(f"\nOn-time delivery rate: {on_time_rate:.1f}%")
```

### 6. Merge: Combining Information

**Mental Model:** Join data from multiple sources to create richer datasets.

Now let's analyze service levels by product category. First, we need to merge our data:

```{python}
#| label: mental-model-6-merge-prep
#| echo: true

# Merge shipment data with product line data
shipments_with_category = (
    clean_shipments
    .merge(product_line_df, on='partID', how='left')  # Left join to keep all shipments
    .assign(
        category_late=lambda df: df['is_late'] & df['productLine'].notna()  # Only count as late if we have category info
    )
)

print(f"After merging: {len(shipments_with_category)} rows")
print(f"Shipments with category info: {shipments_with_category['productLine'].notna().sum()}")
print("\nProduct categories available:")
print(shipments_with_category['productLine'].value_counts())
```

### 7. Split-Apply-Combine: Group Analysis

**Mental Model:** Group data and apply functions within each group.

Now let's analyze service levels by category:

```{python}
#| label: mental-model-7-groupby
#| echo: true

# Analyze service levels by product category
service_by_category = (
    shipments_with_category
    .groupby('productLine')  # Split by product category
    .agg({
        'is_late': ['count', 'sum', 'mean'],  # Count, late count, percentage late
        'days_late': ['mean', 'max']  # Average and max days late
    })
    .round(3)
)

print("Service Level by Product Category:")
print(service_by_category)
```

Let's create a comprehensive analysis by combining shipment-level data with category information:

```{python}
#| label: mental-model-7-comprehensive
#| echo: true

# Create a comprehensive analysis dataset
comprehensive_analysis = (
    shipments_with_category
    .groupby(['shipID', 'productLine'])  # Group by shipment and category
    .agg({
        'is_late': 'any',  # True if any item in this shipment/category is late
        'days_late': 'max'  # Maximum days late for this shipment/category
    })
    .reset_index()
    .assign(
        has_multiple_categories=lambda df: df.groupby('shipID')['productLine'].transform('nunique') > 1
    )
)

print("Comprehensive analysis - shipments with multiple categories:")
multi_category_shipments = comprehensive_analysis[comprehensive_analysis['has_multiple_categories']]
print(f"Shipments with multiple categories: {multi_category_shipments['shipID'].nunique()}")
print(f"Total unique shipments: {comprehensive_analysis['shipID'].nunique()}")
print(f"Percentage with multiple categories: {multi_category_shipments['shipID'].nunique() / comprehensive_analysis['shipID'].nunique() * 100:.1f}%")
```

## Student Analysis Section: Mastering Data Manipulation {#student-analysis-section}

**Your Task:** Demonstrate your mastery of the seven mental models by creating comprehensive analysis and visualizations. You'll need to complete three key components:

### 1. Service Level Analysis by Product Category

**Create a visualization showing:**
- Service level (on-time percentage) by product category
- Average days late by product category
- Do not `echo` the code that creates the visualization

**Add Brief Discussion of the Visualization**
- Which product categories have the best/worst service levels?
- Are there significant differences between categories?
- What business implications does this have for ZappTech?

::: {.callout-important}
## ðŸ“Š Visualization Requirements

Create two plots:
1. **Service Level Bar Chart:** Show on-time percentage by product category
2. **Days Late Box Plot:** Show distribution of days late by product category

Use clear labels and consider using color coding to highlight differences.
:::

### 2. Cross-Category Order Analysis

**Your Task:** Analyze how often customers order products from multiple categories.

**Create one visualization with two side-by-side plots showing:**
- Distribution of categories per shipment
- Percentage of shipments with multiple categories over time

**Your analysis should explain:**
- What percentage of shipments include multiple product categories?
- Are there trends over time in cross-category ordering?
- What does this tell us about customer behavior?

::: {.callout-important}
## ðŸ“Š Cross-Category Analysis Requirements

Create a comprehensive analysis showing:
1. **Category Distribution:** Histogram of number of categories per shipment
2. **Time Series:** Percentage of multi-category shipments over time

- Use the same y-axis scale for comparison if creating side-by-side plots
- Do not `echo` the code that creates the visualization
:::

### 3. Advanced Method Chaining Challenge

**Your Task:** Create a single, complex method chain that demonstrates all seven mental models.

**Create a comprehensive analysis that:**
- Uses all seven mental models in one method chain
- Answers a specific business question
- Shows advanced pandas techniques

**Your analysis should demonstrate:**
- **Assign:** Create new calculated fields
- **Subset:** Filter data based on business logic
- **Drop:** Remove unnecessary columns/rows
- **Sort:** Order results meaningfully
- **Aggregate:** Calculate summary statistics
- **Split-Apply-Combine:** Group analysis
- **Merge:** Combine multiple data sources

::: {.callout-important}
## ðŸ“Š Advanced Method Chaining Requirements

Create a single method chain that:
- Uses all seven mental models
- Answers: "What are the service level trends for each product category over time?"
- Includes at least 8 method calls in the chain
- Produces a meaningful business insight

Show the complete method chain and explain each step.
:::

## Challenge Requirements ðŸ“‹

### Minimum Requirements for Any Points on Challenge

1. **Complete All Seven Mental Models:** Demonstrate each of the seven mental models using method chaining in your analysis.

2. **Create Visualizations:** Complete the three visualization requirements in the Student Analysis Section.

3. **Advanced Method Chain:** Create a single, complex method chain that uses all seven mental models to answer a business question.

4. **Professional Analysis:** Write clear, business-focused analysis that explains your findings and their implications.

## Getting Started: Repository Setup ðŸš€

::: {.callout-important}
## ðŸ“ Getting Started

**Step 1:** Create a new repository in your GitHub account named "dataManipulationChallenge"

**Step 2:** Clone your repository locally using Cursor (or VS Code)

**Step 3:** Copy this `index.qmd` file to your repository

**Step 4:** You're ready to start! The data loading code is already provided.
:::

::: {.callout-tip}
## ðŸ’¡ Why This Challenge Matters

**Real-world Skills:**

- **Method chaining:** The foundation of modern data analysis
- **Business analysis:** Answering real questions with data
- **Code organization:** Writing clean, readable analysis code
- **Problem solving:** Breaking complex questions into manageable steps

**What you'll learn:**
- How to think about data manipulation systematically
- When to use each mental model
- How to combine multiple operations efficiently
- How to write professional data analysis reports
:::

### Getting Started Tips

::: {.callout-note}
## ðŸŽ¯ Method Chaining Philosophy

> "Each operation should build naturally on the previous one"

*Think of method chaining like building with LEGO blocks - each piece connects to the next, creating something more complex and useful than the individual pieces.*
:::

::: {.callout-warning}
## ðŸ’¾ Important: Save Your Work Frequently!

**Before you start:** Make sure to commit your work often using the Source Control panel in Cursor (Ctrl+Shift+G or Cmd+Shift+G). This prevents the AI from overwriting your progress and ensures you don't lose your work.

**Commit after each major step:**

- After completing each mental model section
- After adding your visualizations
- After completing your advanced method chain
- Before asking the AI for help with new code

**How to commit:**

1. Open Source Control panel (Ctrl+Shift+G)
2. Stage your changes (+ button)
3. Write a descriptive commit message
4. Click the checkmark to commit

*Remember: Frequent commits are your safety net!*
:::

## Grading Rubric ðŸŽ“

::: {.callout-important}
## ðŸ“Š What You're Really Being Graded On

**This is a data analysis report, not just a coding exercise.** You're analyzing ZappTech's shipment data and reporting your findings like a professional analyst would. Think of this as a brief you'd write for the CEO about service levels and customer behavior patterns.

**What makes a great report:**

- **Clear narrative:** Tell the story of what you discovered about ZappTech's operations
- **Insightful analysis:** Focus on the most interesting findings about service levels and customer behavior
- **Professional presentation:** Clean, readable, and engaging
- **Concise conclusions:** No AI babble or unnecessary technical jargon
- **Human insights:** Your interpretation of what the data actually means for the business
- **Practical implications:** What ZappTech should do based on your findings

**What we're looking for:** A compelling 2-3 minute read that demonstrates both your data manipulation skills and your ability to extract business insights from data.
:::

### Questions to Answer for 75% Grade on Challenge

1. **Service Level Analysis:** Provide a clear, well-reasoned analysis of service levels by product category. Your analysis should demonstrate understanding of the data and identify meaningful differences between categories.

### Questions to Answer for 85% Grade on Challenge

2. **Cross-Category Analysis:** Provide a thorough analysis of how often customers order from multiple categories. Your analysis should explain what this tells us about customer behavior and business opportunities.

### Questions to Answer for 95% Grade on Challenge

3. **Advanced Method Chaining:** Your analysis should include a sophisticated method chain that demonstrates mastery of all seven mental models. Focus on the technical execution and business value of your analysis.

### Questions to Answer for 100% Grade on Challenge

4. **Professional Presentation:** Your analysis should be written in a professional, engaging style that would be appropriate for a business audience. Use clear visualizations and focus on practical insights rather than technical jargon.

## Submission Checklist âœ…

**Minimum Requirements (Required for Any Points):**

- [ ] Created repository named "dataManipulationChallenge" in your GitHub account
- [ ] Cloned repository locally using Cursor (or VS Code)
- [ ] Completed all three analysis sections with visualizations
- [ ] Document rendered to HTML successfully
- [ ] HTML files uploaded to your repository
- [ ] GitHub Pages enabled and working
- [ ] Site accessible at `https://[your-username].github.io/dataManipulationChallenge/`

**75% Grade Requirements:**

- [ ] Clear analysis of service levels by product category
- [ ] Discussion of business implications for ZappTech

**85% Grade Requirements:**

- [ ] Thorough analysis of cross-category ordering patterns
- [ ] Explanation of what this tells us about customer behavior

**95% Grade Requirements:**

- [ ] Complete advanced method chain using all seven mental models
- [ ] Discussion of technical approach and business value

**100% Grade Requirements:**

- [ ] Professional presentation style appropriate for business audience
- [ ] Clear, engaging narrative that tells a compelling story
- [ ] Practical insights that would help ZappTech's management

**Report Quality (Critical for Higher Grades):**

- [ ] Clear, engaging narrative that tells a story
- [ ] Focus on the most interesting findings about ZappTech's operations
- [ ] Professional writing style (no AI-generated fluff)
- [ ] Concise analysis that gets to the point
- [ ] Practical insights that would help a real business
- [ ] Well-designed visualizations that support your analysis

